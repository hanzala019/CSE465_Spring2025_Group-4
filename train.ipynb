{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
<<<<<<< HEAD
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU found. Running on CPU.\n",
            "\n",
            "Processing Fold 1\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\Python-related\\cse465\\CSE465_Spring2025_Group-4\\myenv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.6694 - val_accuracy: 0.7597 - val_loss: 0.5733\n",
            "Epoch 2/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7606 - loss: 0.5611 - val_accuracy: 0.7679 - val_loss: 0.5517\n",
            "Epoch 3/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.5432 - val_accuracy: 0.7717 - val_loss: 0.5394\n",
            "Epoch 4/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7723 - loss: 0.5293 - val_accuracy: 0.7743 - val_loss: 0.5324\n",
            "Epoch 5/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 0.5289 - val_accuracy: 0.7691 - val_loss: 0.5357\n",
            "Epoch 6/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.5148 - val_accuracy: 0.7768 - val_loss: 0.5320\n",
            "Epoch 7/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.5055 - val_accuracy: 0.7851 - val_loss: 0.5169\n",
            "Epoch 8/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.4926 - val_accuracy: 0.7888 - val_loss: 0.5116\n",
            "Epoch 9/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.4966 - val_accuracy: 0.7890 - val_loss: 0.5082\n",
            "Epoch 10/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.4882 - val_accuracy: 0.7888 - val_loss: 0.5048\n",
            "Epoch 11/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.4743 - val_accuracy: 0.7849 - val_loss: 0.5076\n",
            "Epoch 12/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.4705 - val_accuracy: 0.7863 - val_loss: 0.5106\n",
            "Epoch 13/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8017 - loss: 0.4685 - val_accuracy: 0.7858 - val_loss: 0.5086\n",
            "Epoch 14/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.4635 - val_accuracy: 0.7920 - val_loss: 0.5066\n",
            "Epoch 15/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.4539 - val_accuracy: 0.7918 - val_loss: 0.5031\n",
            "Epoch 16/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8097 - loss: 0.4479 - val_accuracy: 0.7933 - val_loss: 0.5054\n",
            "Epoch 17/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.4423 - val_accuracy: 0.7936 - val_loss: 0.5021\n",
            "Epoch 18/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.4400 - val_accuracy: 0.7926 - val_loss: 0.5063\n",
            "Epoch 19/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4367 - val_accuracy: 0.7969 - val_loss: 0.5050\n",
            "Epoch 20/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.4319 - val_accuracy: 0.7949 - val_loss: 0.5041\n",
            "Epoch 21/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.4282 - val_accuracy: 0.7901 - val_loss: 0.5155\n",
            "Epoch 22/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.4209 - val_accuracy: 0.8001 - val_loss: 0.5033\n",
            "Epoch 23/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4146 - val_accuracy: 0.7964 - val_loss: 0.5119\n",
            "Epoch 24/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.4132 - val_accuracy: 0.7987 - val_loss: 0.5104\n",
            "Epoch 25/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.4057 - val_accuracy: 0.7996 - val_loss: 0.5127\n",
            "Epoch 26/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8355 - loss: 0.3956 - val_accuracy: 0.7981 - val_loss: 0.5211\n",
            "Epoch 27/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8363 - loss: 0.3972 - val_accuracy: 0.8022 - val_loss: 0.5219\n",
            "Epoch 28/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3884 - val_accuracy: 0.8015 - val_loss: 0.5242\n",
            "Epoch 29/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.3918 - val_accuracy: 0.7998 - val_loss: 0.5382\n",
            "Epoch 30/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3883 - val_accuracy: 0.8023 - val_loss: 0.5283\n",
            "Epoch 31/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.3829 - val_accuracy: 0.8050 - val_loss: 0.5297\n",
            "Epoch 32/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8445 - loss: 0.3762 - val_accuracy: 0.8015 - val_loss: 0.5300\n",
            "Epoch 33/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3717 - val_accuracy: 0.8005 - val_loss: 0.5546\n",
            "Epoch 34/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.3712 - val_accuracy: 0.8047 - val_loss: 0.5468\n",
            "Epoch 35/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.3596 - val_accuracy: 0.8008 - val_loss: 0.5445\n",
            "Epoch 36/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.3568 - val_accuracy: 0.8043 - val_loss: 0.5477\n",
            "Epoch 37/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.3548 - val_accuracy: 0.8006 - val_loss: 0.5681\n",
            "Epoch 38/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 0.3477 - val_accuracy: 0.8014 - val_loss: 0.5546\n",
            "Epoch 39/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.3479 - val_accuracy: 0.7985 - val_loss: 0.5735\n",
            "Epoch 40/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.3450 - val_accuracy: 0.8014 - val_loss: 0.5826\n",
            "Epoch 41/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.3451 - val_accuracy: 0.8021 - val_loss: 0.5829\n",
            "Epoch 42/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.3347 - val_accuracy: 0.8064 - val_loss: 0.5807\n",
            "Epoch 43/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8626 - loss: 0.3343 - val_accuracy: 0.8076 - val_loss: 0.5834\n",
            "Epoch 44/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8620 - loss: 0.3355 - val_accuracy: 0.8064 - val_loss: 0.6029\n",
            "Epoch 45/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.3293 - val_accuracy: 0.8067 - val_loss: 0.5820\n",
            "Epoch 46/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3282 - val_accuracy: 0.8040 - val_loss: 0.6095\n",
            "Epoch 47/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.3262 - val_accuracy: 0.8063 - val_loss: 0.6060\n",
            "Epoch 48/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8702 - loss: 0.3168 - val_accuracy: 0.8089 - val_loss: 0.5983\n",
            "Epoch 49/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.3180 - val_accuracy: 0.8082 - val_loss: 0.6144\n",
            "Epoch 50/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8721 - loss: 0.3147 - val_accuracy: 0.8090 - val_loss: 0.6370\n",
            "Fold 1 - Accuracy: 0.8090\n",
            "\n",
            "Processing Fold 2\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\Python-related\\cse465\\CSE465_Spring2025_Group-4\\myenv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7429 - loss: 0.6474 - val_accuracy: 0.7528 - val_loss: 0.5769\n",
            "Epoch 2/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7609 - loss: 0.5593 - val_accuracy: 0.7593 - val_loss: 0.5733\n",
            "Epoch 3/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7719 - loss: 0.5349 - val_accuracy: 0.7591 - val_loss: 0.5567\n",
            "Epoch 4/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7750 - loss: 0.5274 - val_accuracy: 0.7640 - val_loss: 0.5448\n",
            "Epoch 5/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7782 - loss: 0.5181 - val_accuracy: 0.7614 - val_loss: 0.5506\n",
            "Epoch 6/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7830 - loss: 0.5113 - val_accuracy: 0.7737 - val_loss: 0.5329\n",
            "Epoch 7/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7860 - loss: 0.5041 - val_accuracy: 0.7765 - val_loss: 0.5328\n",
            "Epoch 8/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.4943 - val_accuracy: 0.7791 - val_loss: 0.5208\n",
            "Epoch 9/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.4883 - val_accuracy: 0.7820 - val_loss: 0.5164\n",
            "Epoch 10/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.4785 - val_accuracy: 0.7837 - val_loss: 0.5131\n",
            "Epoch 11/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7983 - loss: 0.4767 - val_accuracy: 0.7787 - val_loss: 0.5224\n",
            "Epoch 12/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4694 - val_accuracy: 0.7831 - val_loss: 0.5154\n",
            "Epoch 13/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8042 - loss: 0.4597 - val_accuracy: 0.7861 - val_loss: 0.5145\n",
            "Epoch 14/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.4527 - val_accuracy: 0.7874 - val_loss: 0.5150\n",
            "Epoch 15/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.4449 - val_accuracy: 0.7881 - val_loss: 0.5135\n",
            "Epoch 16/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.4424 - val_accuracy: 0.7927 - val_loss: 0.5020\n",
            "Epoch 17/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.4352 - val_accuracy: 0.7846 - val_loss: 0.5134\n",
            "Epoch 18/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.4336 - val_accuracy: 0.7851 - val_loss: 0.5220\n",
            "Epoch 19/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.4221 - val_accuracy: 0.7910 - val_loss: 0.5094\n",
            "Epoch 20/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.4214 - val_accuracy: 0.7975 - val_loss: 0.5051\n",
            "Epoch 21/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4114 - val_accuracy: 0.7903 - val_loss: 0.5298\n",
            "Epoch 22/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.4080 - val_accuracy: 0.7959 - val_loss: 0.5110\n",
            "Epoch 23/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.4034 - val_accuracy: 0.7908 - val_loss: 0.5184\n",
            "Epoch 24/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.3954 - val_accuracy: 0.7935 - val_loss: 0.5180\n",
            "Epoch 25/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.3891 - val_accuracy: 0.7874 - val_loss: 0.5414\n",
            "Epoch 26/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8370 - loss: 0.3897 - val_accuracy: 0.7961 - val_loss: 0.5232\n",
            "Epoch 27/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.3812 - val_accuracy: 0.7946 - val_loss: 0.5326\n",
            "Epoch 28/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.3797 - val_accuracy: 0.8017 - val_loss: 0.5276\n",
            "Epoch 29/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8467 - loss: 0.3685 - val_accuracy: 0.7942 - val_loss: 0.5409\n",
            "Epoch 30/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.3725 - val_accuracy: 0.7937 - val_loss: 0.5418\n",
            "Epoch 31/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8475 - loss: 0.3678 - val_accuracy: 0.7914 - val_loss: 0.5532\n",
            "Epoch 32/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.3592 - val_accuracy: 0.7971 - val_loss: 0.5506\n",
            "Epoch 33/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.3529 - val_accuracy: 0.7981 - val_loss: 0.5656\n",
            "Epoch 34/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8563 - loss: 0.3495 - val_accuracy: 0.7968 - val_loss: 0.5639\n",
            "Epoch 35/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8578 - loss: 0.3439 - val_accuracy: 0.7980 - val_loss: 0.5575\n",
            "Epoch 36/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.3456 - val_accuracy: 0.7973 - val_loss: 0.5800\n",
            "Epoch 37/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8573 - loss: 0.3423 - val_accuracy: 0.8010 - val_loss: 0.5827\n",
            "Epoch 38/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3318 - val_accuracy: 0.7988 - val_loss: 0.5893\n",
            "Epoch 39/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8615 - loss: 0.3323 - val_accuracy: 0.8015 - val_loss: 0.5918\n",
            "Epoch 40/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3339 - val_accuracy: 0.8024 - val_loss: 0.5981\n",
            "Epoch 41/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.3227 - val_accuracy: 0.8012 - val_loss: 0.5883\n",
            "Epoch 42/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3200 - val_accuracy: 0.7950 - val_loss: 0.6199\n",
            "Epoch 43/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.3161 - val_accuracy: 0.7993 - val_loss: 0.6312\n",
            "Epoch 44/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8699 - loss: 0.3160 - val_accuracy: 0.8006 - val_loss: 0.6284\n",
            "Epoch 45/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.3074 - val_accuracy: 0.8001 - val_loss: 0.6312\n",
            "Epoch 46/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8749 - loss: 0.3050 - val_accuracy: 0.8043 - val_loss: 0.6377\n",
            "Epoch 47/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8734 - loss: 0.3049 - val_accuracy: 0.8006 - val_loss: 0.6450\n",
            "Epoch 48/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8742 - loss: 0.3053 - val_accuracy: 0.7973 - val_loss: 0.6485\n",
            "Epoch 49/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.3082 - val_accuracy: 0.8018 - val_loss: 0.6507\n",
            "Epoch 50/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.2962 - val_accuracy: 0.8013 - val_loss: 0.6833\n",
            "Fold 2 - Accuracy: 0.8013\n",
            "\n",
            "Processing Fold 3\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\Python-related\\cse465\\CSE465_Spring2025_Group-4\\myenv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.6489 - val_accuracy: 0.7547 - val_loss: 0.5806\n",
            "Epoch 2/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7601 - loss: 0.5583 - val_accuracy: 0.7546 - val_loss: 0.5638\n",
            "Epoch 3/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.5455 - val_accuracy: 0.7684 - val_loss: 0.5421\n",
            "Epoch 4/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7740 - loss: 0.5344 - val_accuracy: 0.7635 - val_loss: 0.5466\n",
            "Epoch 5/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7781 - loss: 0.5233 - val_accuracy: 0.7710 - val_loss: 0.5304\n",
            "Epoch 6/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.5116 - val_accuracy: 0.7801 - val_loss: 0.5173\n",
            "Epoch 7/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.5029 - val_accuracy: 0.7814 - val_loss: 0.5146\n",
            "Epoch 8/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.4931 - val_accuracy: 0.7835 - val_loss: 0.5139\n",
            "Epoch 9/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7904 - loss: 0.4921 - val_accuracy: 0.7819 - val_loss: 0.5152\n",
            "Epoch 10/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.4866 - val_accuracy: 0.7852 - val_loss: 0.5112\n",
            "Epoch 11/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.4787 - val_accuracy: 0.7888 - val_loss: 0.5018\n",
            "Epoch 12/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4680 - val_accuracy: 0.7935 - val_loss: 0.4982\n",
            "Epoch 13/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.4660 - val_accuracy: 0.7923 - val_loss: 0.4987\n",
            "Epoch 14/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.4616 - val_accuracy: 0.7963 - val_loss: 0.4940\n",
            "Epoch 15/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.4534 - val_accuracy: 0.7940 - val_loss: 0.4929\n",
            "Epoch 16/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.4491 - val_accuracy: 0.7983 - val_loss: 0.4952\n",
            "Epoch 17/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.4427 - val_accuracy: 0.7964 - val_loss: 0.4933\n",
            "Epoch 18/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8183 - loss: 0.4344 - val_accuracy: 0.7948 - val_loss: 0.4952\n",
            "Epoch 19/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8201 - loss: 0.4291 - val_accuracy: 0.7978 - val_loss: 0.4993\n",
            "Epoch 20/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.4236 - val_accuracy: 0.7940 - val_loss: 0.5005\n",
            "Epoch 21/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8250 - loss: 0.4189 - val_accuracy: 0.7973 - val_loss: 0.4999\n",
            "Epoch 22/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4184 - val_accuracy: 0.7973 - val_loss: 0.5054\n",
            "Epoch 23/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.4075 - val_accuracy: 0.7929 - val_loss: 0.5124\n",
            "Epoch 24/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4133 - val_accuracy: 0.7967 - val_loss: 0.5112\n",
            "Epoch 25/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.3990 - val_accuracy: 0.8004 - val_loss: 0.5065\n",
            "Epoch 26/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.3929 - val_accuracy: 0.7996 - val_loss: 0.5101\n",
            "Epoch 27/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.3928 - val_accuracy: 0.8015 - val_loss: 0.5061\n",
            "Epoch 28/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3923 - val_accuracy: 0.7976 - val_loss: 0.5157\n",
            "Epoch 29/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.3881 - val_accuracy: 0.7965 - val_loss: 0.5237\n",
            "Epoch 30/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8420 - loss: 0.3845 - val_accuracy: 0.8030 - val_loss: 0.5226\n",
            "Epoch 31/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8439 - loss: 0.3738 - val_accuracy: 0.7972 - val_loss: 0.5288\n",
            "Epoch 32/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.3717 - val_accuracy: 0.7963 - val_loss: 0.5321\n",
            "Epoch 33/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.3674 - val_accuracy: 0.7970 - val_loss: 0.5413\n",
            "Epoch 34/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.3629 - val_accuracy: 0.7963 - val_loss: 0.5398\n",
            "Epoch 35/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.3588 - val_accuracy: 0.7990 - val_loss: 0.5453\n",
            "Epoch 36/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8546 - loss: 0.3521 - val_accuracy: 0.8013 - val_loss: 0.5535\n",
            "Epoch 37/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8546 - loss: 0.3490 - val_accuracy: 0.7986 - val_loss: 0.5574\n",
            "Epoch 38/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8575 - loss: 0.3460 - val_accuracy: 0.8042 - val_loss: 0.5563\n",
            "Epoch 39/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8584 - loss: 0.3432 - val_accuracy: 0.8008 - val_loss: 0.5672\n",
            "Epoch 40/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3415 - val_accuracy: 0.8046 - val_loss: 0.5703\n",
            "Epoch 41/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3381 - val_accuracy: 0.7995 - val_loss: 0.5914\n",
            "Epoch 42/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8626 - loss: 0.3362 - val_accuracy: 0.7984 - val_loss: 0.5830\n",
            "Epoch 43/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.3292 - val_accuracy: 0.8053 - val_loss: 0.5842\n",
            "Epoch 44/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8643 - loss: 0.3302 - val_accuracy: 0.8050 - val_loss: 0.5810\n",
            "Epoch 45/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.3261 - val_accuracy: 0.8015 - val_loss: 0.5859\n",
            "Epoch 46/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.3262 - val_accuracy: 0.8063 - val_loss: 0.5850\n",
            "Epoch 47/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3174 - val_accuracy: 0.8017 - val_loss: 0.6104\n",
            "Epoch 48/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8689 - loss: 0.3202 - val_accuracy: 0.8045 - val_loss: 0.6298\n",
            "Epoch 49/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.3155 - val_accuracy: 0.8056 - val_loss: 0.6195\n",
            "Epoch 50/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.3158 - val_accuracy: 0.8059 - val_loss: 0.6258\n",
            "Fold 3 - Accuracy: 0.8059\n",
            "\n",
            "Processing Fold 4\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\Python-related\\cse465\\CSE465_Spring2025_Group-4\\myenv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.6624 - val_accuracy: 0.7629 - val_loss: 0.5540\n",
            "Epoch 2/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7595 - loss: 0.5625 - val_accuracy: 0.7730 - val_loss: 0.5376\n",
            "Epoch 3/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.5515 - val_accuracy: 0.7718 - val_loss: 0.5399\n",
            "Epoch 4/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7662 - loss: 0.5426 - val_accuracy: 0.7833 - val_loss: 0.5185\n",
            "Epoch 5/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7720 - loss: 0.5276 - val_accuracy: 0.7847 - val_loss: 0.5129\n",
            "Epoch 6/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.5185 - val_accuracy: 0.7818 - val_loss: 0.5120\n",
            "Epoch 7/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.5125 - val_accuracy: 0.7858 - val_loss: 0.5029\n",
            "Epoch 8/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7820 - loss: 0.5033 - val_accuracy: 0.7953 - val_loss: 0.4946\n",
            "Epoch 9/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.4945 - val_accuracy: 0.7910 - val_loss: 0.4930\n",
            "Epoch 10/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 0.4876 - val_accuracy: 0.7906 - val_loss: 0.4991\n",
            "Epoch 11/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7923 - loss: 0.4875 - val_accuracy: 0.7981 - val_loss: 0.4946\n",
            "Epoch 12/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.4792 - val_accuracy: 0.7906 - val_loss: 0.4962\n",
            "Epoch 13/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4659 - val_accuracy: 0.7991 - val_loss: 0.4898\n",
            "Epoch 14/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.4702 - val_accuracy: 0.8021 - val_loss: 0.4844\n",
            "Epoch 15/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.4566 - val_accuracy: 0.8010 - val_loss: 0.4910\n",
            "Epoch 16/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8057 - loss: 0.4584 - val_accuracy: 0.8038 - val_loss: 0.4876\n",
            "Epoch 17/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4536 - val_accuracy: 0.8015 - val_loss: 0.4841\n",
            "Epoch 18/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.4418 - val_accuracy: 0.8066 - val_loss: 0.4826\n",
            "Epoch 19/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.4358 - val_accuracy: 0.8048 - val_loss: 0.4825\n",
            "Epoch 20/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8163 - loss: 0.4343 - val_accuracy: 0.7991 - val_loss: 0.4865\n",
            "Epoch 21/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.4289 - val_accuracy: 0.8040 - val_loss: 0.4879\n",
            "Epoch 22/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.4273 - val_accuracy: 0.8007 - val_loss: 0.4893\n",
            "Epoch 23/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.4188 - val_accuracy: 0.8055 - val_loss: 0.4961\n",
            "Epoch 24/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8263 - loss: 0.4102 - val_accuracy: 0.8096 - val_loss: 0.4849\n",
            "Epoch 25/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.4132 - val_accuracy: 0.8080 - val_loss: 0.4895\n",
            "Epoch 26/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.4035 - val_accuracy: 0.8117 - val_loss: 0.4854\n",
            "Epoch 27/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4046 - val_accuracy: 0.8105 - val_loss: 0.4885\n",
            "Epoch 28/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.4017 - val_accuracy: 0.8112 - val_loss: 0.5035\n",
            "Epoch 29/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.3983 - val_accuracy: 0.8098 - val_loss: 0.4933\n",
            "Epoch 30/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3899 - val_accuracy: 0.8094 - val_loss: 0.4955\n",
            "Epoch 31/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.3829 - val_accuracy: 0.8113 - val_loss: 0.5054\n",
            "Epoch 32/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.3759 - val_accuracy: 0.8142 - val_loss: 0.5087\n",
            "Epoch 33/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8432 - loss: 0.3759 - val_accuracy: 0.8154 - val_loss: 0.5011\n",
            "Epoch 34/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.3693 - val_accuracy: 0.8172 - val_loss: 0.5015\n",
            "Epoch 35/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3628 - val_accuracy: 0.8166 - val_loss: 0.5134\n",
            "Epoch 36/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8507 - loss: 0.3604 - val_accuracy: 0.8137 - val_loss: 0.5109\n",
            "Epoch 37/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.3551 - val_accuracy: 0.8132 - val_loss: 0.5309\n",
            "Epoch 38/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3549 - val_accuracy: 0.8170 - val_loss: 0.5096\n",
            "Epoch 39/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8556 - loss: 0.3520 - val_accuracy: 0.8152 - val_loss: 0.5235\n",
            "Epoch 40/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8569 - loss: 0.3473 - val_accuracy: 0.8147 - val_loss: 0.5305\n",
            "Epoch 41/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8559 - loss: 0.3500 - val_accuracy: 0.8160 - val_loss: 0.5369\n",
            "Epoch 42/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8584 - loss: 0.3449 - val_accuracy: 0.8168 - val_loss: 0.5271\n",
            "Epoch 43/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.3413 - val_accuracy: 0.8155 - val_loss: 0.5327\n",
            "Epoch 44/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.3382 - val_accuracy: 0.8160 - val_loss: 0.5476\n",
            "Epoch 45/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8624 - loss: 0.3323 - val_accuracy: 0.8193 - val_loss: 0.5396\n",
            "Epoch 46/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8621 - loss: 0.3345 - val_accuracy: 0.8189 - val_loss: 0.5392\n",
            "Epoch 47/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3329 - val_accuracy: 0.8195 - val_loss: 0.5456\n",
            "Epoch 48/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.3243 - val_accuracy: 0.8204 - val_loss: 0.5435\n",
            "Epoch 49/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.3180 - val_accuracy: 0.8214 - val_loss: 0.5486\n",
            "Epoch 50/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.3189 - val_accuracy: 0.8173 - val_loss: 0.5677\n",
            "Fold 4 - Accuracy: 0.8173\n",
            "\n",
            "Processing Fold 5\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\Python-related\\cse465\\CSE465_Spring2025_Group-4\\myenv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.6596 - val_accuracy: 0.7598 - val_loss: 0.5724\n",
            "Epoch 2/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7564 - loss: 0.5642 - val_accuracy: 0.7675 - val_loss: 0.5435\n",
            "Epoch 3/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7687 - loss: 0.5473 - val_accuracy: 0.7701 - val_loss: 0.5371\n",
            "Epoch 4/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7739 - loss: 0.5305 - val_accuracy: 0.7740 - val_loss: 0.5306\n",
            "Epoch 5/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7800 - loss: 0.5214 - val_accuracy: 0.7798 - val_loss: 0.5170\n",
            "Epoch 6/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.5180 - val_accuracy: 0.7784 - val_loss: 0.5123\n",
            "Epoch 7/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7852 - loss: 0.5046 - val_accuracy: 0.7845 - val_loss: 0.5000\n",
            "Epoch 8/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7884 - loss: 0.5002 - val_accuracy: 0.7935 - val_loss: 0.4909\n",
            "Epoch 9/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7880 - loss: 0.5000 - val_accuracy: 0.7944 - val_loss: 0.4880\n",
            "Epoch 10/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.4903 - val_accuracy: 0.7950 - val_loss: 0.4804\n",
            "Epoch 11/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7892 - loss: 0.4904 - val_accuracy: 0.7956 - val_loss: 0.4826\n",
            "Epoch 12/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7995 - loss: 0.4750 - val_accuracy: 0.7975 - val_loss: 0.4777\n",
            "Epoch 13/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7988 - loss: 0.4741 - val_accuracy: 0.7979 - val_loss: 0.4807\n",
            "Epoch 14/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.4665 - val_accuracy: 0.7983 - val_loss: 0.4760\n",
            "Epoch 15/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.4620 - val_accuracy: 0.7995 - val_loss: 0.4738\n",
            "Epoch 16/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4625 - val_accuracy: 0.8061 - val_loss: 0.4655\n",
            "Epoch 17/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.4583 - val_accuracy: 0.8054 - val_loss: 0.4601\n",
            "Epoch 18/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8089 - loss: 0.4530 - val_accuracy: 0.8122 - val_loss: 0.4583\n",
            "Epoch 19/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.4451 - val_accuracy: 0.8088 - val_loss: 0.4560\n",
            "Epoch 20/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8179 - loss: 0.4382 - val_accuracy: 0.8095 - val_loss: 0.4528\n",
            "Epoch 21/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.4368 - val_accuracy: 0.8121 - val_loss: 0.4486\n",
            "Epoch 22/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.4268 - val_accuracy: 0.8214 - val_loss: 0.4414\n",
            "Epoch 23/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8196 - loss: 0.4272 - val_accuracy: 0.8152 - val_loss: 0.4418\n",
            "Epoch 24/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.4234 - val_accuracy: 0.8176 - val_loss: 0.4450\n",
            "Epoch 25/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8203 - loss: 0.4235 - val_accuracy: 0.8183 - val_loss: 0.4424\n",
            "Epoch 26/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.4147 - val_accuracy: 0.8230 - val_loss: 0.4343\n",
            "Epoch 27/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8290 - loss: 0.4082 - val_accuracy: 0.8214 - val_loss: 0.4348\n",
            "Epoch 28/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.4127 - val_accuracy: 0.8198 - val_loss: 0.4399\n",
            "Epoch 29/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.4083 - val_accuracy: 0.8218 - val_loss: 0.4370\n",
            "Epoch 30/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.3990 - val_accuracy: 0.8251 - val_loss: 0.4288\n",
            "Epoch 31/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3960 - val_accuracy: 0.8287 - val_loss: 0.4228\n",
            "Epoch 32/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.3947 - val_accuracy: 0.8266 - val_loss: 0.4238\n",
            "Epoch 33/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3917 - val_accuracy: 0.8249 - val_loss: 0.4298\n",
            "Epoch 34/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3841 - val_accuracy: 0.8255 - val_loss: 0.4225\n",
            "Epoch 35/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8367 - loss: 0.3851 - val_accuracy: 0.8332 - val_loss: 0.4168\n",
            "Epoch 36/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.3813 - val_accuracy: 0.8330 - val_loss: 0.4178\n",
            "Epoch 37/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.3753 - val_accuracy: 0.8293 - val_loss: 0.4230\n",
            "Epoch 38/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: 0.3734 - val_accuracy: 0.8304 - val_loss: 0.4217\n",
            "Epoch 39/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.3717 - val_accuracy: 0.8353 - val_loss: 0.4154\n",
            "Epoch 40/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.3670 - val_accuracy: 0.8315 - val_loss: 0.4167\n",
            "Epoch 41/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.3662 - val_accuracy: 0.8350 - val_loss: 0.4164\n",
            "Epoch 42/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.3661 - val_accuracy: 0.8356 - val_loss: 0.4172\n",
            "Epoch 43/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.3598 - val_accuracy: 0.8355 - val_loss: 0.4250\n",
            "Epoch 44/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8494 - loss: 0.3586 - val_accuracy: 0.8401 - val_loss: 0.4097\n",
            "Epoch 45/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8526 - loss: 0.3531 - val_accuracy: 0.8382 - val_loss: 0.4093\n",
            "Epoch 46/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.3505 - val_accuracy: 0.8382 - val_loss: 0.4168\n",
            "Epoch 47/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.3492 - val_accuracy: 0.8438 - val_loss: 0.4074\n",
            "Epoch 48/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.3431 - val_accuracy: 0.8422 - val_loss: 0.4081\n",
            "Epoch 49/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3401 - val_accuracy: 0.8442 - val_loss: 0.4121\n",
            "Epoch 50/50\n",
            "\u001b[1m2249/2249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3361 - val_accuracy: 0.8409 - val_loss: 0.4116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Accuracy: 0.8409\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Accuracy: 0.8149\n",
            "Average Precision: 0.8052\n",
            "Average Recall: 0.8149\n",
            "Average F1-Score: 0.8079\n"
          ]
        }
=======
        
>>>>>>> 2519a6ebb02553797846183eb08178dffb4066b9
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from joblib import dump  # For saving preprocessing objects\n",
        "\n",
        "# Configure GPU usage\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    try:\n",
        "        # Enable memory growth to prevent TensorFlow from allocating all GPU memory at once\n",
        "        for device in physical_devices:\n",
        "            tf.config.experimental.set_memory_growth(device, True)\n",
        "        print(f\"Found {len(physical_devices)} GPU(s). CUDA acceleration enabled.\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error configuring GPU: {e}\")\n",
        "else:\n",
        "    print(\"No GPU found. Running on CPU.\")\n",
        "\n",
        "# Load dataset\n",
        "\n",
        "df = pd.read_csv(\"./Augmented_data/combined_trainset.csv\")\n",
        "\n",
        "# Define features and target\n",
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Initialize KFold cross-validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Metrics storage and model saving\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "scaler = None\n",
        "\n",
        "fold_metrics = {\n",
        "    'accuracies': [],\n",
        "    'precisions': [],\n",
        "    'recalls': [],\n",
        "    'f1_scores': []\n",
        "}\n",
        "\n",
        "for fold, (train_ids, val_ids) in enumerate(kfold.split(X)):\n",
        "    print(f\"\\nProcessing Fold {fold + 1}\")\n",
        "    \n",
        "    # Data splitting\n",
        "    X_train, X_val = X[train_ids], X[val_ids]\n",
        "    y_train, y_val = y[train_ids], y[val_ids]\n",
        "    \n",
        "    # Feature scaling\n",
        "    fold_scaler = StandardScaler()\n",
        "    X_train = fold_scaler.fit_transform(X_train)\n",
        "    X_val = fold_scaler.transform(X_val)\n",
        "    \n",
        "    # Ensure data is on GPU if available\n",
        "    X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "    X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
        "    y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "    y_val = tf.convert_to_tensor(y_val, dtype=tf.int32)\n",
        "    \n",
        "    # Model creation\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(len(np.unique(y)), activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    \n",
        "    # Model training with GPU support\n",
        "    with tf.device('/GPU:0'):\n",
        "        history = model.fit(X_train, y_train,\n",
        "                           epochs=50,\n",
        "                           batch_size=32,\n",
        "                           validation_data=(X_val, y_val),\n",
        "                           verbose=1)\n",
        "    \n",
        "    # Evaluation\n",
        "    y_pred = np.argmax(model.predict(X_val, verbose=0), axis=1)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    precision = precision_score(y_val, y_pred, average='weighted')\n",
        "    recall = recall_score(y_val, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    \n",
        "    # Store metrics\n",
        "    fold_metrics['accuracies'].append(accuracy)\n",
        "    fold_metrics['precisions'].append(precision)\n",
        "    fold_metrics['recalls'].append(recall)\n",
        "    fold_metrics['f1_scores'].append(f1)\n",
        "    \n",
        "    # Save best model and scaler\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = model\n",
        "        scaler = fold_scaler\n",
        "\n",
        "    print(f\"Fold {fold + 1} - Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Save final artifacts\n",
        "best_model.save('Model_file/best_model.h5')\n",
        "dump(scaler, 'Model_file/scaler.joblib')\n",
        "dump(label_encoder, 'Model_file/label_encoder.joblib')\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(fold_metrics['accuracies']):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(fold_metrics['precisions']):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(fold_metrics['recalls']):.4f}\")\n",
        "print(f\"Average F1-Score: {np.mean(fold_metrics['f1_scores']):.4f}\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
